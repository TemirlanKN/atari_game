{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4211dd6-0972-4ceb-b77d-1f9bf0d77777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import ale_py\n",
    "import time, os, pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0847373-5b09-4b82-9e09-b1410fb69bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.00015\n",
    "hidden_dim = 256\n",
    "gamma = 0.98\n",
    "epsilon = 1.0\n",
    "epsilon_decay = 0.99\n",
    "epsilon_min = 0.1\n",
    "\n",
    "# Reward Parameters\n",
    "line_clear_reward = 1.5\n",
    "step_penalty = -0.015\n",
    "game_over_penalty = -15.0\n",
    "\n",
    "# Training Episodes\n",
    "num_episodes = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66935c-8f80-40b1-97ab-80f1f90ab2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_action_space', '_cached_spec', '_disable_render_order_enforcing', '_has_reset', '_is_protocol', '_metadata', '_np_random', '_np_random_seed', '_observation_space', '_saved_kwargs', 'action_space', 'class_name', 'close', 'env', 'get_wrapper_attr', 'has_reset', 'has_wrapper_attr', 'metadata', 'np_random', 'np_random_seed', 'observation_space', 'render', 'render_mode', 'reset', 'set_wrapper_attr', 'spec', 'step', 'unwrapped', 'wrapper_spec']\n",
      "5\n",
      "Episode 1: Total Reward = -27.360000000000092, Avg Actor Loss = -0.0193, Avg Critic Loss = 0.2457\n",
      "Episode 2: Total Reward = -21.479999999999958, Avg Actor Loss = 0.0002, Avg Critic Loss = 0.4698\n",
      "Episode 3: Total Reward = -21.119999999999965, Avg Actor Loss = -0.0015, Avg Critic Loss = 0.4972\n",
      "Episode 4: Total Reward = -21.77999999999995, Avg Actor Loss = -0.0037, Avg Critic Loss = 0.4478\n",
      "Episode 5: Total Reward = -23.159999999999933, Avg Actor Loss = -0.0097, Avg Critic Loss = 0.3731\n",
      "Episode 6: Total Reward = -21.35999999999996, Avg Actor Loss = -0.0255, Avg Critic Loss = 0.4777\n",
      "Episode 7: Total Reward = -16.619999999999997, Avg Actor Loss = -0.0760, Avg Critic Loss = 1.8645\n",
      "Episode 8: Total Reward = -16.395, Avg Actor Loss = -0.0893, Avg Critic Loss = 2.1600\n",
      "Episode 9: Total Reward = -16.455, Avg Actor Loss = -0.1093, Avg Critic Loss = 2.0692\n",
      "Episode 10: Total Reward = -16.649999999999995, Avg Actor Loss = -0.1348, Avg Critic Loss = 1.8285\n",
      "Episode 11: Total Reward = -21.119999999999965, Avg Actor Loss = -0.0278, Avg Critic Loss = 0.4962\n",
      "Episode 12: Total Reward = -24.65999999999999, Avg Actor Loss = -0.0213, Avg Critic Loss = 0.3147\n",
      "Episode 13: Total Reward = -25.50000000000002, Avg Actor Loss = -0.0222, Avg Critic Loss = 0.2896\n",
      "Episode 14: Total Reward = -22.499999999999936, Avg Actor Loss = -0.0325, Avg Critic Loss = 0.4053\n",
      "Episode 15: Total Reward = -20.999999999999968, Avg Actor Loss = -0.0447, Avg Critic Loss = 0.5056\n",
      "Episode 16: Total Reward = -21.83999999999995, Avg Actor Loss = -0.0446, Avg Critic Loss = 0.4446\n",
      "Episode 17: Total Reward = -23.57999999999995, Avg Actor Loss = -0.0345, Avg Critic Loss = 0.3543\n",
      "Episode 18: Total Reward = -21.35999999999996, Avg Actor Loss = -0.0496, Avg Critic Loss = 0.4768\n",
      "Episode 19: Total Reward = -23.699999999999953, Avg Actor Loss = -0.0366, Avg Critic Loss = 0.3496\n",
      "Episode 20: Total Reward = -24.299999999999976, Avg Actor Loss = -0.0351, Avg Critic Loss = 0.3269\n",
      "Episode 21: Total Reward = -23.939999999999962, Avg Actor Loss = -0.0372, Avg Critic Loss = 0.3399\n",
      "Episode 22: Total Reward = -16.455, Avg Actor Loss = -0.2256, Avg Critic Loss = 2.0557\n",
      "Episode 23: Total Reward = -16.485, Avg Actor Loss = -0.2224, Avg Critic Loss = 2.0177\n",
      "Episode 24: Total Reward = -24.17999999999997, Avg Actor Loss = -0.0365, Avg Critic Loss = 0.3307\n",
      "Episode 25: Total Reward = -16.634999999999998, Avg Actor Loss = -0.2031, Avg Critic Loss = 1.8363\n",
      "Episode 26: Total Reward = -16.485, Avg Actor Loss = -0.2242, Avg Critic Loss = 2.0231\n",
      "Episode 27: Total Reward = -24.599999999999987, Avg Actor Loss = -0.0351, Avg Critic Loss = 0.3168\n",
      "Episode 28: Total Reward = -16.439999999999998, Avg Actor Loss = -0.2313, Avg Critic Loss = 2.0709\n",
      "Episode 29: Total Reward = -24.059999999999967, Avg Actor Loss = -0.0372, Avg Critic Loss = 0.3347\n",
      "Episode 30: Total Reward = -16.499999999999996, Avg Actor Loss = -0.2231, Avg Critic Loss = 1.9949\n",
      "Episode 31: Total Reward = -21.77999999999995, Avg Actor Loss = -0.0499, Avg Critic Loss = 0.4469\n",
      "Episode 32: Total Reward = -22.73999999999993, Avg Actor Loss = -0.0436, Avg Critic Loss = 0.3913\n",
      "Episode 33: Total Reward = -23.819999999999958, Avg Actor Loss = -0.0386, Avg Critic Loss = 0.3456\n",
      "Episode 34: Total Reward = -22.619999999999933, Avg Actor Loss = -0.0461, Avg Critic Loss = 0.3981\n",
      "Episode 35: Total Reward = -21.89999999999995, Avg Actor Loss = -0.0487, Avg Critic Loss = 0.4388\n",
      "Episode 36: Total Reward = -21.599999999999955, Avg Actor Loss = -0.0514, Avg Critic Loss = 0.4613\n",
      "Episode 37: Total Reward = -21.599999999999955, Avg Actor Loss = -0.0511, Avg Critic Loss = 0.4576\n",
      "Episode 38: Total Reward = -25.620000000000026, Avg Actor Loss = -0.0332, Avg Critic Loss = 0.2862\n",
      "Episode 39: Total Reward = -23.63999999999995, Avg Actor Loss = -0.0390, Avg Critic Loss = 0.3506\n",
      "Episode 40: Total Reward = -16.994999999999994, Avg Actor Loss = -0.1679, Avg Critic Loss = 1.4960\n",
      "Episode 41: Total Reward = -22.25999999999994, Avg Actor Loss = -0.0465, Avg Critic Loss = 0.4162\n",
      "Episode 42: Total Reward = -24.11999999999997, Avg Actor Loss = -0.0370, Avg Critic Loss = 0.3320\n",
      "Episode 43: Total Reward = -22.634999999999934, Avg Actor Loss = -0.0444, Avg Critic Loss = 0.3965\n",
      "Episode 44: Total Reward = -23.819999999999958, Avg Actor Loss = -0.0382, Avg Critic Loss = 0.3431\n",
      "Episode 45: Total Reward = -22.979999999999926, Avg Actor Loss = -0.0423, Avg Critic Loss = 0.3781\n",
      "Episode 46: Total Reward = -20.51999999999998, Avg Actor Loss = -0.0612, Avg Critic Loss = 0.5467\n",
      "Episode 47: Total Reward = -23.459999999999944, Avg Actor Loss = -0.0399, Avg Critic Loss = 0.3569\n",
      "Episode 48: Total Reward = -16.439999999999998, Avg Actor Loss = -0.2318, Avg Critic Loss = 2.0478\n",
      "Episode 49: Total Reward = -22.199999999999942, Avg Actor Loss = -0.0468, Avg Critic Loss = 0.4179\n",
      "Episode 50: Total Reward = -25.380000000000017, Avg Actor Loss = -0.0326, Avg Critic Loss = 0.2907\n",
      "Episode 51: Total Reward = -23.939999999999962, Avg Actor Loss = -0.0378, Avg Critic Loss = 0.3373\n",
      "Episode 52: Total Reward = -16.739999999999995, Avg Actor Loss = -0.1923, Avg Critic Loss = 1.6943\n",
      "Episode 53: Total Reward = -20.819999999999972, Avg Actor Loss = -0.0578, Avg Critic Loss = 0.5129\n",
      "Episode 54: Total Reward = -24.779999999999994, Avg Actor Loss = -0.0346, Avg Critic Loss = 0.3082\n",
      "Episode 55: Total Reward = -25.20000000000001, Avg Actor Loss = -0.0333, Avg Critic Loss = 0.2951\n",
      "Episode 56: Total Reward = -24.9, Avg Actor Loss = -0.0342, Avg Critic Loss = 0.3053\n",
      "Episode 57: Total Reward = -21.944999999999947, Avg Actor Loss = -0.0493, Avg Critic Loss = 0.4365\n",
      "Episode 58: Total Reward = -21.83999999999995, Avg Actor Loss = -0.0492, Avg Critic Loss = 0.4364\n",
      "Episode 59: Total Reward = -25.320000000000014, Avg Actor Loss = -0.0327, Avg Critic Loss = 0.2915\n",
      "Episode 60: Total Reward = -23.57999999999995, Avg Actor Loss = -0.0398, Avg Critic Loss = 0.3538\n",
      "Episode 61: Total Reward = -22.199999999999942, Avg Actor Loss = -0.0472, Avg Critic Loss = 0.4202\n",
      "Episode 62: Total Reward = -24.299999999999976, Avg Actor Loss = -0.0368, Avg Critic Loss = 0.3255\n",
      "Episode 63: Total Reward = -26.160000000000046, Avg Actor Loss = -0.0308, Avg Critic Loss = 0.2718\n",
      "Episode 64: Total Reward = -26.700000000000067, Avg Actor Loss = -0.0291, Avg Critic Loss = 0.2596\n",
      "Episode 65: Total Reward = -21.89999999999995, Avg Actor Loss = -0.0493, Avg Critic Loss = 0.4393\n",
      "Episode 66: Total Reward = -25.560000000000024, Avg Actor Loss = -0.0322, Avg Critic Loss = 0.2879\n",
      "Episode 67: Total Reward = -21.659999999999954, Avg Actor Loss = -0.0508, Avg Critic Loss = 0.4514\n",
      "Episode 68: Total Reward = -22.559999999999935, Avg Actor Loss = -0.0449, Avg Critic Loss = 0.3988\n",
      "Episode 69: Total Reward = -23.219999999999935, Avg Actor Loss = -0.0415, Avg Critic Loss = 0.3704\n",
      "Episode 70: Total Reward = -24.194999999999972, Avg Actor Loss = -0.0373, Avg Critic Loss = 0.3284\n",
      "Episode 71: Total Reward = -21.29999999999996, Avg Actor Loss = -0.0540, Avg Critic Loss = 0.4800\n",
      "Episode 72: Total Reward = -23.39999999999994, Avg Actor Loss = -0.0402, Avg Critic Loss = 0.3587\n",
      "Episode 73: Total Reward = -24.539999999999985, Avg Actor Loss = -0.0356, Avg Critic Loss = 0.3161\n",
      "Episode 74: Total Reward = -24.314999999999976, Avg Actor Loss = -0.0368, Avg Critic Loss = 0.3233\n",
      "Episode 75: Total Reward = -22.079999999999945, Avg Actor Loss = -0.0478, Avg Critic Loss = 0.4230\n",
      "Episode 76: Total Reward = -23.819999999999958, Avg Actor Loss = -0.0384, Avg Critic Loss = 0.3414\n",
      "Episode 77: Total Reward = -21.77999999999995, Avg Actor Loss = -0.0503, Avg Critic Loss = 0.4431\n",
      "Episode 78: Total Reward = -21.659999999999954, Avg Actor Loss = -0.0505, Avg Critic Loss = 0.4501\n",
      "Episode 79: Total Reward = -22.73999999999993, Avg Actor Loss = -0.0438, Avg Critic Loss = 0.3905\n",
      "Episode 80: Total Reward = -21.41999999999996, Avg Actor Loss = -0.0526, Avg Critic Loss = 0.4658\n",
      "Episode 81: Total Reward = -21.659999999999954, Avg Actor Loss = -0.0509, Avg Critic Loss = 0.4467\n",
      "Episode 82: Total Reward = -21.959999999999948, Avg Actor Loss = -0.0482, Avg Critic Loss = 0.4242\n",
      "Episode 83: Total Reward = -26.340000000000053, Avg Actor Loss = -0.0299, Avg Critic Loss = 0.2662\n",
      "Episode 84: Total Reward = -22.73999999999993, Avg Actor Loss = -0.0441, Avg Critic Loss = 0.3943\n",
      "Episode 85: Total Reward = -20.999999999999968, Avg Actor Loss = -0.0566, Avg Critic Loss = 0.4993\n",
      "Episode 86: Total Reward = -16.859999999999996, Avg Actor Loss = -0.1788, Avg Critic Loss = 1.5610\n",
      "Episode 87: Total Reward = -16.499999999999996, Avg Actor Loss = -0.2211, Avg Critic Loss = 1.9270\n",
      "Episode 88: Total Reward = -22.73999999999993, Avg Actor Loss = -0.0436, Avg Critic Loss = 0.3867\n",
      "Episode 89: Total Reward = -22.439999999999937, Avg Actor Loss = -0.0460, Avg Critic Loss = 0.4073\n",
      "Episode 90: Total Reward = -22.079999999999945, Avg Actor Loss = -0.0479, Avg Critic Loss = 0.4245\n",
      "Episode 91: Total Reward = -21.239999999999963, Avg Actor Loss = -0.0542, Avg Critic Loss = 0.4792\n",
      "Episode 92: Total Reward = -16.694999999999997, Avg Actor Loss = -0.1994, Avg Critic Loss = 1.7727\n",
      "Episode 93: Total Reward = -25.920000000000037, Avg Actor Loss = -0.0312, Avg Critic Loss = 0.2772\n",
      "Episode 94: Total Reward = -22.619999999999933, Avg Actor Loss = -0.0447, Avg Critic Loss = 0.3968\n",
      "Episode 95: Total Reward = -21.89999999999995, Avg Actor Loss = -0.0494, Avg Critic Loss = 0.4424\n",
      "Episode 96: Total Reward = -21.29999999999996, Avg Actor Loss = -0.0541, Avg Critic Loss = 0.4798\n",
      "Episode 97: Total Reward = -16.619999999999997, Avg Actor Loss = -0.2088, Avg Critic Loss = 1.8560\n",
      "Episode 98: Total Reward = -24.299999999999976, Avg Actor Loss = -0.0366, Avg Critic Loss = 0.3244\n",
      "Episode 99: Total Reward = -22.979999999999926, Avg Actor Loss = -0.0427, Avg Critic Loss = 0.3797\n",
      "Episode 100: Total Reward = -21.599999999999955, Avg Actor Loss = -0.0517, Avg Critic Loss = 0.4622\n",
      "Episode 101: Total Reward = -20.93999999999997, Avg Actor Loss = -0.0572, Avg Critic Loss = 0.5063\n",
      "Episode 102: Total Reward = -16.499999999999996, Avg Actor Loss = -0.2253, Avg Critic Loss = 2.0062\n",
      "Episode 103: Total Reward = -25.005000000000003, Avg Actor Loss = -0.0341, Avg Critic Loss = 0.3028\n",
      "Episode 104: Total Reward = -25.815000000000033, Avg Actor Loss = -0.0317, Avg Critic Loss = 0.2781\n",
      "Episode 105: Total Reward = -23.219999999999935, Avg Actor Loss = -0.0411, Avg Critic Loss = 0.3645\n",
      "Episode 106: Total Reward = -21.35999999999996, Avg Actor Loss = -0.0532, Avg Critic Loss = 0.4702\n",
      "Episode 107: Total Reward = -24.599999999999987, Avg Actor Loss = -0.0352, Avg Critic Loss = 0.3125\n",
      "Episode 108: Total Reward = -20.819999999999972, Avg Actor Loss = -0.0580, Avg Critic Loss = 0.5120\n",
      "Episode 109: Total Reward = -27.660000000000103, Avg Actor Loss = -0.0267, Avg Critic Loss = 0.2365\n",
      "Episode 110: Total Reward = -27.5400000000001, Avg Actor Loss = -0.0271, Avg Critic Loss = 0.2399\n",
      "Episode 111: Total Reward = -20.87999999999997, Avg Actor Loss = -0.0581, Avg Critic Loss = 0.5092\n",
      "Episode 112: Total Reward = -22.37999999999994, Avg Actor Loss = -0.0456, Avg Critic Loss = 0.4043\n",
      "Episode 113: Total Reward = -22.079999999999945, Avg Actor Loss = -0.0481, Avg Critic Loss = 0.4303\n",
      "Episode 114: Total Reward = -26.160000000000046, Avg Actor Loss = -0.0306, Avg Critic Loss = 0.2703\n",
      "Episode 115: Total Reward = -16.499999999999996, Avg Actor Loss = -0.2246, Avg Critic Loss = 1.9901\n",
      "Episode 116: Total Reward = -22.37999999999994, Avg Actor Loss = -0.0459, Avg Critic Loss = 0.4081\n",
      "Episode 117: Total Reward = -21.959999999999948, Avg Actor Loss = -0.0486, Avg Critic Loss = 0.4290\n",
      "Episode 118: Total Reward = -16.979999999999993, Avg Actor Loss = -0.1693, Avg Critic Loss = 1.4791\n",
      "Episode 119: Total Reward = -26.340000000000053, Avg Actor Loss = -0.0298, Avg Critic Loss = 0.2648\n",
      "Episode 120: Total Reward = -26.460000000000058, Avg Actor Loss = -0.0298, Avg Critic Loss = 0.2633\n",
      "Episode 121: Total Reward = -22.619999999999933, Avg Actor Loss = -0.0448, Avg Critic Loss = 0.3985\n",
      "Episode 122: Total Reward = -21.41999999999996, Avg Actor Loss = -0.0530, Avg Critic Loss = 0.4684\n",
      "Episode 123: Total Reward = -21.959999999999948, Avg Actor Loss = -0.0485, Avg Critic Loss = 0.4318\n",
      "Episode 124: Total Reward = -25.20000000000001, Avg Actor Loss = -0.0333, Avg Critic Loss = 0.2943\n",
      "Episode 125: Total Reward = -23.219999999999935, Avg Actor Loss = -0.0413, Avg Critic Loss = 0.3655\n",
      "Episode 126: Total Reward = -21.41999999999996, Avg Actor Loss = -0.0527, Avg Critic Loss = 0.4654\n",
      "Episode 127: Total Reward = -21.599999999999955, Avg Actor Loss = -0.0511, Avg Critic Loss = 0.4500\n",
      "Episode 128: Total Reward = -17.415, Avg Actor Loss = -0.1397, Avg Critic Loss = 1.2296\n",
      "Episode 129: Total Reward = -26.460000000000058, Avg Actor Loss = -0.0296, Avg Critic Loss = 0.2634\n",
      "Episode 130: Total Reward = -25.680000000000028, Avg Actor Loss = -0.0319, Avg Critic Loss = 0.2825\n",
      "Episode 131: Total Reward = -20.93999999999997, Avg Actor Loss = -0.0569, Avg Critic Loss = 0.5010\n",
      "Episode 132: Total Reward = -22.37999999999994, Avg Actor Loss = -0.0458, Avg Critic Loss = 0.4046\n",
      "Episode 133: Total Reward = -16.664999999999996, Avg Actor Loss = -0.1997, Avg Critic Loss = 1.7244\n",
      "Episode 134: Total Reward = -23.519999999999946, Avg Actor Loss = -0.0397, Avg Critic Loss = 0.3519\n",
      "Episode 135: Total Reward = -22.139999999999944, Avg Actor Loss = -0.0473, Avg Critic Loss = 0.4167\n",
      "Episode 136: Total Reward = -21.959999999999948, Avg Actor Loss = -0.0486, Avg Critic Loss = 0.4310\n",
      "Episode 137: Total Reward = -21.479999999999958, Avg Actor Loss = -0.0522, Avg Critic Loss = 0.4580\n",
      "Episode 138: Total Reward = -16.499999999999996, Avg Actor Loss = -0.2214, Avg Critic Loss = 1.9198\n",
      "Episode 139: Total Reward = -28.020000000000117, Avg Actor Loss = -0.0260, Avg Critic Loss = 0.2310\n",
      "Episode 140: Total Reward = -27.480000000000096, Avg Actor Loss = -0.0271, Avg Critic Loss = 0.2376\n",
      "Episode 141: Total Reward = -21.85499999999995, Avg Actor Loss = -0.0494, Avg Critic Loss = 0.4343\n",
      "Episode 142: Total Reward = -24.239999999999974, Avg Actor Loss = -0.0366, Avg Critic Loss = 0.3242\n",
      "Episode 143: Total Reward = -20.579999999999977, Avg Actor Loss = -0.0604, Avg Critic Loss = 0.5324\n",
      "Episode 144: Total Reward = -21.77999999999995, Avg Actor Loss = -0.0501, Avg Critic Loss = 0.4430\n",
      "Episode 145: Total Reward = -26.040000000000042, Avg Actor Loss = -0.0306, Avg Critic Loss = 0.2701\n",
      "Episode 146: Total Reward = -23.039999999999928, Avg Actor Loss = -0.0423, Avg Critic Loss = 0.3743\n",
      "Episode 147: Total Reward = -20.93999999999997, Avg Actor Loss = -0.0567, Avg Critic Loss = 0.4976\n",
      "Episode 148: Total Reward = -16.499999999999996, Avg Actor Loss = -0.2232, Avg Critic Loss = 1.9595\n",
      "Episode 149: Total Reward = -23.159999999999933, Avg Actor Loss = -0.0411, Avg Critic Loss = 0.3629\n",
      "Episode 150: Total Reward = -25.320000000000014, Avg Actor Loss = -0.0328, Avg Critic Loss = 0.2882\n",
      "Episode 151: Total Reward = -23.33999999999994, Avg Actor Loss = -0.0406, Avg Critic Loss = 0.3558\n",
      "Episode 152: Total Reward = -23.57999999999995, Avg Actor Loss = -0.0393, Avg Critic Loss = 0.3477\n",
      "Episode 153: Total Reward = -21.539999999999957, Avg Actor Loss = -0.0513, Avg Critic Loss = 0.4503\n",
      "Episode 154: Total Reward = -24.599999999999987, Avg Actor Loss = -0.0353, Avg Critic Loss = 0.3106\n",
      "Episode 155: Total Reward = -21.539999999999957, Avg Actor Loss = -0.0521, Avg Critic Loss = 0.4530\n",
      "Episode 156: Total Reward = -23.939999999999962, Avg Actor Loss = -0.0373, Avg Critic Loss = 0.3269\n",
      "Episode 157: Total Reward = -25.140000000000008, Avg Actor Loss = -0.0331, Avg Critic Loss = 0.2900\n",
      "Episode 158: Total Reward = -21.659999999999954, Avg Actor Loss = -0.0504, Avg Critic Loss = 0.4431\n",
      "Episode 159: Total Reward = -21.29999999999996, Avg Actor Loss = -0.0536, Avg Critic Loss = 0.4706\n",
      "Episode 160: Total Reward = -23.039999999999928, Avg Actor Loss = -0.0416, Avg Critic Loss = 0.3644\n",
      "Episode 161: Total Reward = -25.260000000000012, Avg Actor Loss = -0.0328, Avg Critic Loss = 0.2893\n",
      "Episode 162: Total Reward = -21.539999999999957, Avg Actor Loss = -0.0518, Avg Critic Loss = 0.4503\n",
      "Episode 163: Total Reward = -21.569999999999958, Avg Actor Loss = -0.0515, Avg Critic Loss = 0.4500\n",
      "Episode 164: Total Reward = -21.479999999999958, Avg Actor Loss = -0.0518, Avg Critic Loss = 0.4573\n",
      "Episode 165: Total Reward = -22.979999999999926, Avg Actor Loss = -0.0429, Avg Critic Loss = 0.3856\n",
      "Episode 166: Total Reward = -24.41999999999998, Avg Actor Loss = -0.0359, Avg Critic Loss = 0.3154\n",
      "Episode 167: Total Reward = -21.119999999999965, Avg Actor Loss = -0.0546, Avg Critic Loss = 0.4767\n",
      "Episode 168: Total Reward = -22.139999999999944, Avg Actor Loss = -0.0476, Avg Critic Loss = 0.4251\n",
      "Episode 169: Total Reward = -24.11999999999997, Avg Actor Loss = -0.0371, Avg Critic Loss = 0.3265\n",
      "Episode 170: Total Reward = -27.120000000000083, Avg Actor Loss = -0.0279, Avg Critic Loss = 0.2465\n",
      "Episode 171: Total Reward = -20.819999999999972, Avg Actor Loss = -0.0581, Avg Critic Loss = 0.5097\n",
      "Episode 172: Total Reward = -16.664999999999996, Avg Actor Loss = -0.1987, Avg Critic Loss = 1.7045\n",
      "Episode 173: Total Reward = -24.599999999999987, Avg Actor Loss = -0.0352, Avg Critic Loss = 0.3117\n",
      "Episode 174: Total Reward = -21.719999999999953, Avg Actor Loss = -0.0502, Avg Critic Loss = 0.4410\n",
      "Episode 175: Total Reward = -22.25999999999994, Avg Actor Loss = -0.0464, Avg Critic Loss = 0.4082\n",
      "Episode 176: Total Reward = -22.31999999999994, Avg Actor Loss = -0.0465, Avg Critic Loss = 0.4149\n",
      "Episode 177: Total Reward = -16.574999999999996, Avg Actor Loss = -0.2129, Avg Critic Loss = 1.8404\n",
      "Episode 178: Total Reward = -22.079999999999945, Avg Actor Loss = -0.0475, Avg Critic Loss = 0.4234\n",
      "Episode 179: Total Reward = -24.41999999999998, Avg Actor Loss = -0.0358, Avg Critic Loss = 0.3132\n",
      "Episode 180: Total Reward = -23.87999999999996, Avg Actor Loss = -0.0380, Avg Critic Loss = 0.3347\n",
      "Episode 181: Total Reward = -21.719999999999953, Avg Actor Loss = -0.0508, Avg Critic Loss = 0.4521\n",
      "Episode 182: Total Reward = -21.239999999999963, Avg Actor Loss = -0.0538, Avg Critic Loss = 0.4717\n",
      "Episode 183: Total Reward = -16.38, Avg Actor Loss = -0.2361, Avg Critic Loss = 1.9933\n",
      "Episode 184: Total Reward = -24.11999999999997, Avg Actor Loss = -0.0364, Avg Critic Loss = 0.3221\n",
      "Episode 185: Total Reward = -23.219999999999935, Avg Actor Loss = -0.0410, Avg Critic Loss = 0.3603\n",
      "Episode 186: Total Reward = -16.634999999999998, Avg Actor Loss = -0.2046, Avg Critic Loss = 1.7617\n",
      "Episode 187: Total Reward = -21.539999999999957, Avg Actor Loss = -0.0509, Avg Critic Loss = 0.4472\n",
      "Episode 188: Total Reward = -22.019999999999946, Avg Actor Loss = -0.0481, Avg Critic Loss = 0.4223\n",
      "Episode 189: Total Reward = -23.87999999999996, Avg Actor Loss = -0.0375, Avg Critic Loss = 0.3287\n",
      "Episode 190: Total Reward = -22.499999999999936, Avg Actor Loss = -0.0449, Avg Critic Loss = 0.3938\n",
      "Episode 191: Total Reward = -22.199999999999942, Avg Actor Loss = -0.0471, Avg Critic Loss = 0.4136\n",
      "Episode 192: Total Reward = -16.38, Avg Actor Loss = -0.2388, Avg Critic Loss = 2.0444\n",
      "Episode 193: Total Reward = -25.20000000000001, Avg Actor Loss = -0.0329, Avg Critic Loss = 0.2940\n",
      "Episode 194: Total Reward = -27.420000000000094, Avg Actor Loss = -0.0273, Avg Critic Loss = 0.2411\n",
      "Episode 195: Total Reward = -21.37499999999996, Avg Actor Loss = -0.0539, Avg Critic Loss = 0.4770\n",
      "Episode 196: Total Reward = -22.439999999999937, Avg Actor Loss = -0.0455, Avg Critic Loss = 0.4034\n",
      "Episode 197: Total Reward = -22.85999999999993, Avg Actor Loss = -0.0428, Avg Critic Loss = 0.3768\n",
      "Episode 198: Total Reward = -21.29999999999996, Avg Actor Loss = -0.0533, Avg Critic Loss = 0.4679\n",
      "Episode 199: Total Reward = -23.819999999999958, Avg Actor Loss = -0.0381, Avg Critic Loss = 0.3335\n",
      "Episode 200: Total Reward = -25.920000000000037, Avg Actor Loss = -0.0309, Avg Critic Loss = 0.2732\n",
      "Episode 201: Total Reward = -22.73999999999993, Avg Actor Loss = -0.0440, Avg Critic Loss = 0.3870\n",
      "Episode 202: Total Reward = -20.999999999999968, Avg Actor Loss = -0.0556, Avg Critic Loss = 0.4841\n",
      "Episode 203: Total Reward = -16.38, Avg Actor Loss = -0.2393, Avg Critic Loss = 2.0659\n",
      "Episode 204: Total Reward = -21.059999999999967, Avg Actor Loss = -0.0550, Avg Critic Loss = 0.4847\n",
      "Episode 205: Total Reward = -22.73999999999993, Avg Actor Loss = -0.0434, Avg Critic Loss = 0.3814\n",
      "Episode 206: Total Reward = -21.179999999999964, Avg Actor Loss = -0.0545, Avg Critic Loss = 0.4719\n",
      "Episode 207: Total Reward = -20.639999999999976, Avg Actor Loss = -0.0591, Avg Critic Loss = 0.5169\n",
      "Episode 208: Total Reward = -16.499999999999996, Avg Actor Loss = -0.2145, Avg Critic Loss = 1.7932\n",
      "Episode 209: Total Reward = -21.83999999999995, Avg Actor Loss = -0.0483, Avg Critic Loss = 0.4256\n",
      "Episode 210: Total Reward = -22.439999999999937, Avg Actor Loss = -0.0448, Avg Critic Loss = 0.3919\n",
      "Episode 211: Total Reward = -21.29999999999996, Avg Actor Loss = -0.0539, Avg Critic Loss = 0.4705\n",
      "Episode 212: Total Reward = -16.439999999999998, Avg Actor Loss = -0.2300, Avg Critic Loss = 1.9728\n",
      "Episode 213: Total Reward = -21.89999999999995, Avg Actor Loss = -0.0491, Avg Critic Loss = 0.4390\n",
      "Episode 214: Total Reward = -23.819999999999958, Avg Actor Loss = -0.0381, Avg Critic Loss = 0.3369\n",
      "Episode 215: Total Reward = -24.65999999999999, Avg Actor Loss = -0.0349, Avg Critic Loss = 0.3068\n",
      "Episode 216: Total Reward = -22.979999999999926, Avg Actor Loss = -0.0431, Avg Critic Loss = 0.3833\n",
      "Episode 217: Total Reward = -16.724999999999994, Avg Actor Loss = -0.1930, Avg Critic Loss = 1.6589\n",
      "Episode 218: Total Reward = -22.25999999999994, Avg Actor Loss = -0.0457, Avg Critic Loss = 0.3986\n",
      "Episode 219: Total Reward = -25.380000000000017, Avg Actor Loss = -0.0322, Avg Critic Loss = 0.2853\n",
      "Episode 220: Total Reward = -22.85999999999993, Avg Actor Loss = -0.0431, Avg Critic Loss = 0.3772\n",
      "Episode 221: Total Reward = -20.759999999999973, Avg Actor Loss = -0.0583, Avg Critic Loss = 0.5070\n",
      "Episode 222: Total Reward = -16.964999999999996, Avg Actor Loss = -0.1681, Avg Critic Loss = 1.4301\n",
      "Episode 223: Total Reward = -22.619999999999933, Avg Actor Loss = -0.0442, Avg Critic Loss = 0.3896\n",
      "Episode 224: Total Reward = -22.499999999999936, Avg Actor Loss = -0.0445, Avg Critic Loss = 0.3946\n",
      "Episode 225: Total Reward = -25.020000000000003, Avg Actor Loss = -0.0336, Avg Critic Loss = 0.2964\n",
      "Episode 226: Total Reward = -23.39999999999994, Avg Actor Loss = -0.0402, Avg Critic Loss = 0.3505\n",
      "Episode 227: Total Reward = -17.219999999999995, Avg Actor Loss = -0.1514, Avg Critic Loss = 1.3277\n",
      "Episode 228: Total Reward = -21.29999999999996, Avg Actor Loss = -0.0539, Avg Critic Loss = 0.4770\n",
      "Episode 229: Total Reward = -16.439999999999998, Avg Actor Loss = -0.2290, Avg Critic Loss = 1.9463\n",
      "Episode 230: Total Reward = -24.239999999999974, Avg Actor Loss = -0.0358, Avg Critic Loss = 0.3160\n",
      "Episode 231: Total Reward = -20.87999999999997, Avg Actor Loss = -0.0578, Avg Critic Loss = 0.5069\n",
      "Episode 232: Total Reward = -23.57999999999995, Avg Actor Loss = -0.0390, Avg Critic Loss = 0.3417\n",
      "Episode 233: Total Reward = -16.485, Avg Actor Loss = -0.2228, Avg Critic Loss = 1.8908\n",
      "Episode 234: Total Reward = -21.329999999999963, Avg Actor Loss = -0.0528, Avg Critic Loss = 0.4636\n",
      "Episode 235: Total Reward = -21.539999999999957, Avg Actor Loss = -0.0511, Avg Critic Loss = 0.4519\n",
      "Episode 236: Total Reward = -20.87999999999997, Avg Actor Loss = -0.0569, Avg Critic Loss = 0.4969\n",
      "Episode 237: Total Reward = -24.239999999999974, Avg Actor Loss = -0.0362, Avg Critic Loss = 0.3202\n",
      "Episode 238: Total Reward = -21.479999999999958, Avg Actor Loss = -0.0525, Avg Critic Loss = 0.4581\n",
      "Episode 239: Total Reward = -26.400000000000055, Avg Actor Loss = -0.0294, Avg Critic Loss = 0.2614\n",
      "Episode 240: Total Reward = -22.619999999999933, Avg Actor Loss = -0.0443, Avg Critic Loss = 0.3867\n",
      "Episode 241: Total Reward = -20.819999999999972, Avg Actor Loss = -0.0578, Avg Critic Loss = 0.5041\n",
      "Episode 242: Total Reward = -17.144999999999996, Avg Actor Loss = -0.1507, Avg Critic Loss = 1.2505\n",
      "Episode 243: Total Reward = -22.85999999999993, Avg Actor Loss = -0.0430, Avg Critic Loss = 0.3828\n",
      "Episode 244: Total Reward = -22.679999999999932, Avg Actor Loss = -0.0441, Avg Critic Loss = 0.3854\n",
      "Episode 245: Total Reward = -27.420000000000094, Avg Actor Loss = -0.0271, Avg Critic Loss = 0.2396\n",
      "Episode 246: Total Reward = -23.39999999999994, Avg Actor Loss = -0.0402, Avg Critic Loss = 0.3531\n",
      "Episode 247: Total Reward = -20.999999999999968, Avg Actor Loss = -0.0557, Avg Critic Loss = 0.4828\n",
      "Episode 248: Total Reward = -16.904999999999994, Avg Actor Loss = -0.1714, Avg Critic Loss = 1.4387\n",
      "Episode 249: Total Reward = -22.559999999999935, Avg Actor Loss = -0.0436, Avg Critic Loss = 0.3812\n",
      "Episode 250: Total Reward = -25.140000000000008, Avg Actor Loss = -0.0332, Avg Critic Loss = 0.2934\n",
      "Episode 251: Total Reward = -21.059999999999967, Avg Actor Loss = -0.0553, Avg Critic Loss = 0.4766\n",
      "Episode 252: Total Reward = -22.37999999999994, Avg Actor Loss = -0.0463, Avg Critic Loss = 0.4120\n",
      "Episode 253: Total Reward = -16.799999999999997, Avg Actor Loss = -0.1834, Avg Critic Loss = 1.5604\n",
      "Episode 254: Total Reward = -16.275, Avg Actor Loss = -0.2529, Avg Critic Loss = 2.1154\n",
      "Episode 255: Total Reward = -20.699999999999974, Avg Actor Loss = -0.0583, Avg Critic Loss = 0.5169\n",
      "Episode 256: Total Reward = -22.31999999999994, Avg Actor Loss = -0.0462, Avg Critic Loss = 0.4031\n",
      "Episode 257: Total Reward = -23.39999999999994, Avg Actor Loss = -0.0403, Avg Critic Loss = 0.3583\n",
      "Episode 258: Total Reward = -21.35999999999996, Avg Actor Loss = -0.0529, Avg Critic Loss = 0.4625\n",
      "Episode 259: Total Reward = -26.580000000000062, Avg Actor Loss = -0.0292, Avg Critic Loss = 0.2589\n",
      "Episode 260: Total Reward = -23.819999999999958, Avg Actor Loss = -0.0384, Avg Critic Loss = 0.3356\n",
      "Episode 261: Total Reward = -22.25999999999994, Avg Actor Loss = -0.0469, Avg Critic Loss = 0.4116\n",
      "Episode 262: Total Reward = -16.724999999999994, Avg Actor Loss = -0.1906, Avg Critic Loss = 1.6183\n",
      "Episode 263: Total Reward = -20.999999999999968, Avg Actor Loss = -0.0553, Avg Critic Loss = 0.4822\n",
      "Episode 264: Total Reward = -25.320000000000014, Avg Actor Loss = -0.0326, Avg Critic Loss = 0.2908\n",
      "Episode 265: Total Reward = -22.79999999999993, Avg Actor Loss = -0.0438, Avg Critic Loss = 0.3868\n",
      "Episode 266: Total Reward = -21.659999999999954, Avg Actor Loss = -0.0507, Avg Critic Loss = 0.4420\n",
      "Episode 267: Total Reward = -16.844999999999995, Avg Actor Loss = -0.1757, Avg Critic Loss = 1.4642\n",
      "Episode 268: Total Reward = -21.659999999999954, Avg Actor Loss = -0.0507, Avg Critic Loss = 0.4472\n",
      "Episode 269: Total Reward = -26.52000000000006, Avg Actor Loss = -0.0288, Avg Critic Loss = 0.2539\n",
      "Episode 270: Total Reward = -25.44000000000002, Avg Actor Loss = -0.0323, Avg Critic Loss = 0.2859\n",
      "Episode 271: Total Reward = -21.41999999999996, Avg Actor Loss = -0.0534, Avg Critic Loss = 0.4660\n",
      "Episode 272: Total Reward = -16.514999999999997, Avg Actor Loss = -0.2180, Avg Critic Loss = 1.8602\n",
      "Episode 273: Total Reward = -20.594999999999978, Avg Actor Loss = -0.0597, Avg Critic Loss = 0.5183\n",
      "Episode 274: Total Reward = -21.539999999999957, Avg Actor Loss = -0.0509, Avg Critic Loss = 0.4475\n",
      "Episode 275: Total Reward = -24.779999999999994, Avg Actor Loss = -0.0342, Avg Critic Loss = 0.3021\n",
      "Episode 276: Total Reward = -21.059999999999967, Avg Actor Loss = -0.0555, Avg Critic Loss = 0.4822\n",
      "Episode 277: Total Reward = -24.17999999999997, Avg Actor Loss = -0.0363, Avg Critic Loss = 0.3192\n",
      "Episode 278: Total Reward = -22.919999999999927, Avg Actor Loss = -0.0433, Avg Critic Loss = 0.3838\n"
     ]
    }
   ],
   "source": [
    "gym.register_envs(ale_py)\n",
    "env = gym.make(\"ALE/Tetris-v5\", render_mode=\"human\")\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "state, _ = env.reset()\n",
    "save_dir = \"training_logs2\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "print(dir(env))\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, action_dim, hidden_dim=128):\n",
    "        super(Actor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
    "\n",
    "        # Use a dummy input to calculate the flattened size after conv layers\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 3, state.shape[0], state.shape[1])\n",
    "            conv_output = self.conv_layers(dummy_input)\n",
    "            conv_output_size = conv_output.view(-1).size(0)\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(conv_output_size, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "    def conv_layers(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = self.conv_layers(state)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        action_probs = torch.softmax(self.fc2(x), dim=-1)\n",
    "        return action_probs\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super(Critic, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=4, stride=2)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 3, state.shape[0], state.shape[1])\n",
    "            conv_output = self.conv_layers(dummy_input)\n",
    "            conv_output_size = conv_output.view(-1).size(0)\n",
    "\n",
    "        self.fc1 = nn.Linear(conv_output_size, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def conv_layers(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = self.conv_layers(state)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        state_value = self.fc2(x)\n",
    "        return state_value\n",
    "\n",
    "def calculate_reward(lines_cleared, game_over):\n",
    "    if game_over:\n",
    "        return game_over_penalty\n",
    "    elif lines_cleared > 0:\n",
    "        return line_clear_reward * lines_cleared\n",
    "    else:\n",
    "        return step_penalty\n",
    "\n",
    "def train_step(state, action, reward, next_state, done):\n",
    "    state = torch.tensor(state, dtype=torch.float32).unsqueeze(0).permute(0, 3, 1, 2) / 255.0\n",
    "    next_state = torch.tensor(next_state, dtype=torch.float32).unsqueeze(0).permute(0, 3, 1, 2) / 255.0\n",
    "    action = torch.tensor(action, dtype=torch.long)\n",
    "    reward = torch.tensor(reward, dtype=torch.float32)\n",
    "\n",
    "    # Critic update with gradient clipping\n",
    "    value = critic(state)\n",
    "    next_value = critic(next_state) * (1 - done)\n",
    "    target_value = reward + gamma * next_value\n",
    "    critic_loss = (value - target_value.detach()) ** 2\n",
    "\n",
    "    critic_optimizer.zero_grad()\n",
    "    critic_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(critic.parameters(), max_norm=1.0)\n",
    "    critic_optimizer.step()\n",
    "\n",
    "    # Actor update with gradient clipping\n",
    "    advantage = (target_value - value).detach()\n",
    "    action_probs = actor(state)\n",
    "    log_prob = torch.log(action_probs.squeeze(0)[action])\n",
    "    actor_loss = -log_prob * advantage\n",
    "\n",
    "    actor_optimizer.zero_grad()\n",
    "    actor_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(actor.parameters(), max_norm=1.0)\n",
    "    actor_optimizer.step()\n",
    "\n",
    "    return actor_loss.item(), critic_loss.item()\n",
    "\n",
    "# Actor and Critic networks and optimizers\n",
    "actor = Actor(action_dim=env.action_space.n)\n",
    "critic = Critic()\n",
    "actor_optimizer = optim.Adam(actor.parameters(), lr=learning_rate)\n",
    "critic_optimizer = optim.Adam(critic.parameters(), lr=learning_rate)\n",
    "print(action_dim)\n",
    "\n",
    "# parameters and metrics\n",
    "def save_parameters_and_metrics(episode, actor, critic, actor_optimizer, critic_optimizer, metrics):\n",
    "    torch.save({\n",
    "        'actor_state_dict': actor.state_dict(),\n",
    "        'critic_state_dict': critic.state_dict(),\n",
    "        'actor_optimizer_state_dict': actor_optimizer.state_dict(),\n",
    "        'critic_optimizer_state_dict': critic_optimizer.state_dict()\n",
    "    }, os.path.join(save_dir, f\"model_checkpoint_ep{episode}.pt\"))\n",
    "\n",
    "    with open(os.path.join(save_dir, \"training_metrics.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(metrics, f)\n",
    "\n",
    "metrics = {\n",
    "    \"episode_rewards\": [],\n",
    "    \"step_actor_losses\": [],\n",
    "    \"step_critic_losses\": []\n",
    "}\n",
    "\n",
    "# Define a function to print the average weights and losses\n",
    "def print_parameters_and_losses(actor, critic, episode, avg_actor_loss, avg_critic_loss):\n",
    "    print(f\"\\n--- Statistics at Episode {episode} ---\")\n",
    "    \n",
    "    # Print the average weight of specific layers\n",
    "    actor_conv1_avg = actor.conv1.weight.data.mean().item()\n",
    "    print(f\"Actor Layer 1 Conv Weights Average: {actor_conv1_avg}\")\n",
    "    \n",
    "    actor_fc1_avg = actor.fc1.weight.data.mean().item()\n",
    "    print(f\"Actor Layer 1 FC Weights Average: {actor_fc1_avg}\")\n",
    "    \n",
    "    critic_conv1_avg = critic.conv1.weight.data.mean().item()\n",
    "    print(f\"Critic Layer 1 Conv Weights Average: {critic_conv1_avg}\")\n",
    "    \n",
    "    critic_fc1_avg = critic.fc1.weight.data.mean().item()\n",
    "    print(f\"Critic Layer 1 FC Weights Average: {critic_fc1_avg}\")\n",
    "\n",
    "    # Print average losses for actor and critic\n",
    "    print(f\"Average Actor Loss: {avg_actor_loss}\")\n",
    "    print(f\"Average Critic Loss: {avg_critic_loss}\")\n",
    "    \n",
    "    print(\"--- End of Statistics ---\\n\")\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    actor_losses = []\n",
    "    critic_losses = []\n",
    "\n",
    "    while not done:\n",
    "        # Preprocess state for model input\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).permute(0, 3, 1, 2) / 255.0\n",
    "\n",
    "        # Get action probabilities from the actor network\n",
    "        action_probs = actor(state_tensor).detach().numpy().squeeze()\n",
    "\n",
    "        # Îµ-greedy action selection\n",
    "        if np.random.rand() < epsilon:\n",
    "            # Exploration: choose a random action\n",
    "            action = np.random.choice(action_dim)\n",
    "        else:\n",
    "            # Exploitation: choose the action with the highest probability\n",
    "            action = np.argmax(action_probs)\n",
    "\n",
    "        # Decay epsilon after each step\n",
    "        epsilon = max(epsilon * epsilon_decay, epsilon_min)\n",
    "\n",
    "        # Take the action in the environment\n",
    "        next_state, _, done, _, info = env.step(action)\n",
    "        \n",
    "        # Calculate reward\n",
    "        lines_cleared = info.get(\"lines_cleared\", 0)\n",
    "        reward = calculate_reward(lines_cleared, done)\n",
    "        episode_reward += reward\n",
    "\n",
    "        # Train actor and critic networks\n",
    "        actor_loss, critic_loss = train_step(state, action, reward, next_state, done)\n",
    "\n",
    "        # Log losses for each step\n",
    "        actor_losses.append(actor_loss)\n",
    "        critic_losses.append(critic_loss)\n",
    "\n",
    "        # Update the state\n",
    "        state = next_state\n",
    "\n",
    "    # Calculate average losses for this episode\n",
    "    avg_actor_loss = np.mean(actor_losses)\n",
    "    avg_critic_loss = np.mean(critic_losses)\n",
    "\n",
    "    # Print the episode results with average losses\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {episode_reward}, Avg Actor Loss = {avg_actor_loss:.4f}, Avg Critic Loss = {avg_critic_loss:.4f}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87c97c9-18d4-46ce-b93c-01afbe056b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
