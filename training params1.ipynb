{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64be2fb1-ea06-4849-b227-4f78b9730d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import ale_py\n",
    "import time, os, pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a5c4de9-269e-49de-8f01-b0acdf5a76b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.0001\n",
    "hidden_dim = 128\n",
    "gamma = 0.99\n",
    "epsilon = 1.0\n",
    "epsilon_decay = 0.995\n",
    "epsilon_min = 0.1\n",
    "\n",
    "# Reward Parameters\n",
    "line_clear_reward = 1.0\n",
    "step_penalty = -0.01\n",
    "game_over_penalty = -10.0\n",
    "\n",
    "# Training Episodes\n",
    "num_episodes = 1000\n",
    "frame_skip = 4\n",
    "print_interval = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9565d8a7-8922-40dc-95ea-7520d4f5642f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_action_space', '_cached_spec', '_disable_render_order_enforcing', '_has_reset', '_is_protocol', '_metadata', '_np_random', '_np_random_seed', '_observation_space', '_saved_kwargs', 'action_space', 'class_name', 'close', 'env', 'get_wrapper_attr', 'has_reset', 'has_wrapper_attr', 'metadata', 'np_random', 'np_random_seed', 'observation_space', 'render', 'render_mode', 'reset', 'set_wrapper_attr', 'spec', 'step', 'unwrapped', 'wrapper_spec']\n",
      "5\n",
      "Episode 1: Total Reward = -16.439999999999905, Avg Actor Loss = -0.0221, Avg Critic Loss = 0.1243\n",
      "Episode 2: Total Reward = -15.959999999999917, Avg Actor Loss = nan, Avg Critic Loss = 0.1340\n",
      "Episode 3: Total Reward = -14.799999999999942, Avg Actor Loss = nan, Avg Critic Loss = 0.1676\n",
      "Episode 4: Total Reward = -15.559999999999926, Avg Actor Loss = nan, Avg Critic Loss = 0.1452\n",
      "Episode 5: Total Reward = -16.109999999999914, Avg Actor Loss = nan, Avg Critic Loss = 0.1322\n",
      "Episode 6: Total Reward = -15.439999999999928, Avg Actor Loss = nan, Avg Critic Loss = 0.1482\n",
      "Episode 7: Total Reward = -15.319999999999931, Avg Actor Loss = nan, Avg Critic Loss = 0.1515\n",
      "Episode 8: Total Reward = -16.23999999999991, Avg Actor Loss = nan, Avg Critic Loss = 0.1286\n",
      "Episode 9: Total Reward = -18.51999999999986, Avg Actor Loss = nan, Avg Critic Loss = 0.0943\n",
      "Episode 10: Total Reward = -14.319999999999952, Avg Actor Loss = nan, Avg Critic Loss = 0.1847\n",
      "Episode 11: Total Reward = -16.359999999999907, Avg Actor Loss = nan, Avg Critic Loss = 0.1273\n",
      "Episode 12: Total Reward = -16.559999999999903, Avg Actor Loss = nan, Avg Critic Loss = 0.1227\n",
      "Episode 13: Total Reward = -15.279999999999932, Avg Actor Loss = nan, Avg Critic Loss = 0.1535\n",
      "Episode 14: Total Reward = -17.799999999999876, Avg Actor Loss = nan, Avg Critic Loss = 0.1033\n",
      "Episode 15: Total Reward = -16.23999999999991, Avg Actor Loss = nan, Avg Critic Loss = 0.1288\n",
      "Episode 16: Total Reward = -15.679999999999923, Avg Actor Loss = nan, Avg Critic Loss = 0.1406\n",
      "Episode 17: Total Reward = -16.15999999999991, Avg Actor Loss = nan, Avg Critic Loss = 0.1295\n",
      "Episode 18: Total Reward = -15.879999999999919, Avg Actor Loss = nan, Avg Critic Loss = 0.1369\n",
      "Episode 19: Total Reward = -14.87999999999994, Avg Actor Loss = nan, Avg Critic Loss = 0.1641\n",
      "Episode 20: Total Reward = -14.989999999999938, Avg Actor Loss = nan, Avg Critic Loss = 0.1599\n",
      "Episode 21: Total Reward = -18.199999999999868, Avg Actor Loss = nan, Avg Critic Loss = 0.0970\n",
      "Episode 22: Total Reward = -15.83999999999992, Avg Actor Loss = nan, Avg Critic Loss = 0.1367\n",
      "Episode 23: Total Reward = -14.959999999999939, Avg Actor Loss = nan, Avg Critic Loss = 0.1583\n",
      "Episode 24: Total Reward = -15.35999999999993, Avg Actor Loss = nan, Avg Critic Loss = 0.1491\n",
      "Episode 25: Total Reward = -17.279999999999887, Avg Actor Loss = nan, Avg Critic Loss = 0.1105\n",
      "Episode 26: Total Reward = -15.83999999999992, Avg Actor Loss = nan, Avg Critic Loss = 0.1356\n",
      "Episode 27: Total Reward = -16.359999999999907, Avg Actor Loss = nan, Avg Critic Loss = 0.1244\n",
      "Episode 28: Total Reward = -14.87999999999994, Avg Actor Loss = nan, Avg Critic Loss = 0.1594\n",
      "Episode 29: Total Reward = -14.999999999999938, Avg Actor Loss = nan, Avg Critic Loss = 0.1597\n",
      "Episode 30: Total Reward = -17.15999999999989, Avg Actor Loss = nan, Avg Critic Loss = 0.1110\n",
      "Episode 31: Total Reward = -16.27999999999991, Avg Actor Loss = nan, Avg Critic Loss = 0.1250\n",
      "Episode 32: Total Reward = -17.799999999999876, Avg Actor Loss = nan, Avg Critic Loss = 0.1018\n",
      "Episode 33: Total Reward = -14.839999999999941, Avg Actor Loss = nan, Avg Critic Loss = 0.1625\n",
      "Episode 34: Total Reward = -16.559999999999903, Avg Actor Loss = nan, Avg Critic Loss = 0.1214\n",
      "Episode 35: Total Reward = -17.959999999999873, Avg Actor Loss = nan, Avg Critic Loss = 0.0995\n",
      "Episode 36: Total Reward = -16.039999999999914, Avg Actor Loss = nan, Avg Critic Loss = 0.1305\n",
      "Episode 37: Total Reward = -16.519999999999904, Avg Actor Loss = nan, Avg Critic Loss = 0.1212\n",
      "Episode 38: Total Reward = -14.959999999999939, Avg Actor Loss = nan, Avg Critic Loss = 0.1598\n",
      "Episode 39: Total Reward = -16.919999999999895, Avg Actor Loss = nan, Avg Critic Loss = 0.1153\n",
      "Episode 40: Total Reward = -14.87999999999994, Avg Actor Loss = nan, Avg Critic Loss = 0.1619\n",
      "Episode 41: Total Reward = -15.879999999999919, Avg Actor Loss = nan, Avg Critic Loss = 0.1334\n",
      "Episode 42: Total Reward = -15.639999999999924, Avg Actor Loss = nan, Avg Critic Loss = 0.1395\n",
      "Episode 43: Total Reward = -14.279999999999953, Avg Actor Loss = nan, Avg Critic Loss = 0.1832\n",
      "Episode 44: Total Reward = -16.6399999999999, Avg Actor Loss = nan, Avg Critic Loss = 0.1194\n",
      "Episode 45: Total Reward = -16.27999999999991, Avg Actor Loss = nan, Avg Critic Loss = 0.1265\n",
      "Episode 46: Total Reward = -15.599999999999925, Avg Actor Loss = nan, Avg Critic Loss = 0.1398\n",
      "Episode 47: Total Reward = -15.439999999999928, Avg Actor Loss = nan, Avg Critic Loss = 0.1452\n",
      "Episode 48: Total Reward = -15.679999999999923, Avg Actor Loss = nan, Avg Critic Loss = 0.1385\n",
      "Episode 49: Total Reward = -15.239999999999933, Avg Actor Loss = nan, Avg Critic Loss = 0.1485\n",
      "Episode 50: Total Reward = -16.19999999999991, Avg Actor Loss = nan, Avg Critic Loss = 0.1268\n",
      "Episode 51: Total Reward = -14.959999999999939, Avg Actor Loss = nan, Avg Critic Loss = 0.1593\n",
      "Episode 52: Total Reward = -16.7599999999999, Avg Actor Loss = nan, Avg Critic Loss = 0.1169\n",
      "Episode 53: Total Reward = -15.919999999999918, Avg Actor Loss = nan, Avg Critic Loss = 0.1335\n",
      "Episode 54: Total Reward = -14.079999999999957, Avg Actor Loss = nan, Avg Critic Loss = 0.1910\n",
      "Episode 55: Total Reward = -16.27999999999991, Avg Actor Loss = nan, Avg Critic Loss = 0.1285\n",
      "Episode 56: Total Reward = -15.959999999999917, Avg Actor Loss = nan, Avg Critic Loss = 0.1333\n",
      "Episode 57: Total Reward = -14.999999999999938, Avg Actor Loss = nan, Avg Critic Loss = 0.1566\n",
      "Episode 58: Total Reward = -17.15999999999989, Avg Actor Loss = nan, Avg Critic Loss = 0.1108\n",
      "Episode 59: Total Reward = -15.039999999999937, Avg Actor Loss = nan, Avg Critic Loss = 0.1556\n",
      "Episode 60: Total Reward = -17.16999999999989, Avg Actor Loss = nan, Avg Critic Loss = 0.1091\n",
      "Episode 61: Total Reward = -15.679999999999923, Avg Actor Loss = nan, Avg Critic Loss = 0.1376\n",
      "Episode 62: Total Reward = -16.059999999999917, Avg Actor Loss = nan, Avg Critic Loss = 0.1304\n",
      "Episode 63: Total Reward = -15.479999999999928, Avg Actor Loss = nan, Avg Critic Loss = 0.1437\n",
      "Episode 64: Total Reward = -14.87999999999994, Avg Actor Loss = nan, Avg Critic Loss = 0.1619\n",
      "Episode 65: Total Reward = -15.199999999999934, Avg Actor Loss = nan, Avg Critic Loss = 0.1495\n",
      "Episode 66: Total Reward = -16.599999999999902, Avg Actor Loss = nan, Avg Critic Loss = 0.1188\n",
      "Episode 67: Total Reward = -13.839999999999963, Avg Actor Loss = nan, Avg Critic Loss = 0.1998\n",
      "Episode 68: Total Reward = -14.199999999999955, Avg Actor Loss = nan, Avg Critic Loss = 0.1791\n",
      "Episode 69: Total Reward = -14.999999999999938, Avg Actor Loss = nan, Avg Critic Loss = 0.1555\n",
      "Episode 70: Total Reward = -18.239999999999867, Avg Actor Loss = nan, Avg Critic Loss = 0.0953\n",
      "Episode 71: Total Reward = -14.759999999999943, Avg Actor Loss = nan, Avg Critic Loss = 0.1630\n",
      "Episode 72: Total Reward = -15.879999999999919, Avg Actor Loss = nan, Avg Critic Loss = 0.1307\n",
      "Episode 73: Total Reward = -18.51999999999986, Avg Actor Loss = nan, Avg Critic Loss = 0.0929\n",
      "Episode 74: Total Reward = -15.439999999999928, Avg Actor Loss = nan, Avg Critic Loss = 0.1413\n",
      "Episode 75: Total Reward = -15.559999999999926, Avg Actor Loss = nan, Avg Critic Loss = 0.1379\n",
      "Episode 76: Total Reward = -16.319999999999908, Avg Actor Loss = nan, Avg Critic Loss = 0.1221\n",
      "Episode 77: Total Reward = -16.959999999999894, Avg Actor Loss = nan, Avg Critic Loss = 0.1124\n",
      "Episode 78: Total Reward = -15.999999999999917, Avg Actor Loss = nan, Avg Critic Loss = 0.1317\n",
      "Episode 79: Total Reward = -15.79999999999992, Avg Actor Loss = nan, Avg Critic Loss = 0.1334\n",
      "Episode 80: Total Reward = -14.86999999999994, Avg Actor Loss = nan, Avg Critic Loss = 0.1560\n",
      "Episode 81: Total Reward = -17.919999999999874, Avg Actor Loss = nan, Avg Critic Loss = 0.0993\n",
      "Episode 82: Total Reward = -17.039999999999893, Avg Actor Loss = nan, Avg Critic Loss = 0.1108\n",
      "Episode 83: Total Reward = -17.999999999999872, Avg Actor Loss = nan, Avg Critic Loss = 0.0965\n",
      "Episode 84: Total Reward = -15.999999999999917, Avg Actor Loss = nan, Avg Critic Loss = 0.1287\n",
      "Episode 85: Total Reward = -16.559999999999903, Avg Actor Loss = nan, Avg Critic Loss = 0.1177\n",
      "Episode 86: Total Reward = -16.7199999999999, Avg Actor Loss = nan, Avg Critic Loss = 0.1144\n",
      "Episode 87: Total Reward = -14.719999999999944, Avg Actor Loss = nan, Avg Critic Loss = 0.1608\n",
      "Episode 88: Total Reward = -18.51999999999986, Avg Actor Loss = nan, Avg Critic Loss = 0.0886\n",
      "Episode 89: Total Reward = -16.41999999999991, Avg Actor Loss = nan, Avg Critic Loss = 0.1193\n",
      "Episode 90: Total Reward = -16.19999999999991, Avg Actor Loss = nan, Avg Critic Loss = 0.1266\n",
      "Episode 91: Total Reward = -16.27999999999991, Avg Actor Loss = nan, Avg Critic Loss = 0.1257\n",
      "Episode 92: Total Reward = -16.919999999999895, Avg Actor Loss = nan, Avg Critic Loss = 0.1117\n",
      "Episode 93: Total Reward = -17.439999999999884, Avg Actor Loss = nan, Avg Critic Loss = 0.1045\n",
      "Episode 94: Total Reward = -15.079999999999936, Avg Actor Loss = nan, Avg Critic Loss = 0.1509\n",
      "Episode 95: Total Reward = -14.839999999999941, Avg Actor Loss = nan, Avg Critic Loss = 0.1570\n",
      "Episode 96: Total Reward = -14.759999999999943, Avg Actor Loss = nan, Avg Critic Loss = 0.1631\n",
      "Episode 97: Total Reward = -15.539999999999926, Avg Actor Loss = nan, Avg Critic Loss = 0.1385\n",
      "Episode 98: Total Reward = -14.959999999999939, Avg Actor Loss = nan, Avg Critic Loss = 0.1546\n",
      "Episode 99: Total Reward = -15.559999999999926, Avg Actor Loss = nan, Avg Critic Loss = 0.1373\n",
      "Episode 100: Total Reward = -16.739999999999903, Avg Actor Loss = nan, Avg Critic Loss = 0.1158\n",
      "Episode 101: Total Reward = -15.439999999999928, Avg Actor Loss = nan, Avg Critic Loss = 0.1429\n",
      "Episode 102: Total Reward = -16.919999999999895, Avg Actor Loss = nan, Avg Critic Loss = 0.1114\n",
      "Episode 103: Total Reward = -16.799999999999898, Avg Actor Loss = nan, Avg Critic Loss = 0.1105\n",
      "Episode 104: Total Reward = -14.479999999999949, Avg Actor Loss = nan, Avg Critic Loss = 0.1700\n",
      "Episode 105: Total Reward = -14.759999999999943, Avg Actor Loss = nan, Avg Critic Loss = 0.1591\n",
      "Episode 106: Total Reward = -16.6399999999999, Avg Actor Loss = nan, Avg Critic Loss = 0.1121\n",
      "Episode 107: Total Reward = -15.279999999999932, Avg Actor Loss = nan, Avg Critic Loss = 0.1429\n",
      "Episode 108: Total Reward = -16.519999999999904, Avg Actor Loss = nan, Avg Critic Loss = 0.1166\n",
      "Episode 109: Total Reward = -15.479999999999928, Avg Actor Loss = nan, Avg Critic Loss = 0.1363\n",
      "Episode 110: Total Reward = -16.399999999999906, Avg Actor Loss = nan, Avg Critic Loss = 0.1166\n",
      "Episode 111: Total Reward = -14.87999999999994, Avg Actor Loss = nan, Avg Critic Loss = 0.1567\n",
      "Episode 112: Total Reward = -15.279999999999932, Avg Actor Loss = nan, Avg Critic Loss = 0.1440\n",
      "Episode 113: Total Reward = -18.51999999999986, Avg Actor Loss = nan, Avg Critic Loss = 0.0905\n",
      "Episode 114: Total Reward = -15.699999999999923, Avg Actor Loss = nan, Avg Critic Loss = 0.1325\n",
      "Episode 115: Total Reward = -18.399999999999864, Avg Actor Loss = nan, Avg Critic Loss = 0.0877\n",
      "Episode 116: Total Reward = -16.479999999999905, Avg Actor Loss = nan, Avg Critic Loss = 0.1141\n",
      "Episode 117: Total Reward = -15.79999999999992, Avg Actor Loss = nan, Avg Critic Loss = 0.1293\n",
      "Episode 118: Total Reward = -17.319999999999887, Avg Actor Loss = nan, Avg Critic Loss = 0.1045\n",
      "Episode 119: Total Reward = -17.07999999999989, Avg Actor Loss = nan, Avg Critic Loss = 0.1037\n",
      "Episode 120: Total Reward = -14.799999999999942, Avg Actor Loss = nan, Avg Critic Loss = 0.1589\n",
      "Episode 121: Total Reward = -16.919999999999895, Avg Actor Loss = nan, Avg Critic Loss = 0.1121\n",
      "Episode 122: Total Reward = -16.319999999999908, Avg Actor Loss = nan, Avg Critic Loss = 0.1237\n",
      "Episode 123: Total Reward = -15.679999999999923, Avg Actor Loss = nan, Avg Critic Loss = 0.1322\n",
      "Episode 124: Total Reward = -15.83999999999992, Avg Actor Loss = nan, Avg Critic Loss = 0.1294\n",
      "Episode 125: Total Reward = -15.679999999999923, Avg Actor Loss = nan, Avg Critic Loss = 0.1286\n",
      "Episode 126: Total Reward = -13.639999999999967, Avg Actor Loss = nan, Avg Critic Loss = 0.2038\n",
      "Episode 127: Total Reward = -13.99999999999996, Avg Actor Loss = nan, Avg Critic Loss = 0.1899\n",
      "Episode 128: Total Reward = -17.279999999999887, Avg Actor Loss = nan, Avg Critic Loss = 0.1050\n",
      "Episode 129: Total Reward = -15.159999999999934, Avg Actor Loss = nan, Avg Critic Loss = 0.1373\n",
      "Episode 130: Total Reward = -16.559999999999903, Avg Actor Loss = nan, Avg Critic Loss = 0.1107\n",
      "Episode 131: Total Reward = -17.109999999999893, Avg Actor Loss = nan, Avg Critic Loss = 0.1044\n",
      "Episode 132: Total Reward = -16.799999999999898, Avg Actor Loss = nan, Avg Critic Loss = 0.1157\n",
      "Episode 133: Total Reward = -17.23999999999989, Avg Actor Loss = nan, Avg Critic Loss = 0.1055\n",
      "Episode 134: Total Reward = -13.879999999999962, Avg Actor Loss = nan, Avg Critic Loss = 0.1866\n",
      "Episode 135: Total Reward = -17.55999999999988, Avg Actor Loss = nan, Avg Critic Loss = 0.1005\n",
      "Episode 136: Total Reward = -15.159999999999934, Avg Actor Loss = nan, Avg Critic Loss = 0.1466\n",
      "Episode 137: Total Reward = -15.159999999999934, Avg Actor Loss = nan, Avg Critic Loss = 0.1466\n",
      "Episode 138: Total Reward = -15.879999999999919, Avg Actor Loss = nan, Avg Critic Loss = 0.1237\n",
      "Episode 139: Total Reward = -15.559999999999926, Avg Actor Loss = nan, Avg Critic Loss = 0.1333\n",
      "Episode 140: Total Reward = -15.279999999999932, Avg Actor Loss = nan, Avg Critic Loss = 0.1365\n",
      "Episode 141: Total Reward = -18.399999999999864, Avg Actor Loss = nan, Avg Critic Loss = 0.0891\n",
      "Episode 142: Total Reward = -14.199999999999955, Avg Actor Loss = nan, Avg Critic Loss = 0.1807\n",
      "Episode 143: Total Reward = -17.279999999999887, Avg Actor Loss = nan, Avg Critic Loss = 0.1056\n",
      "Episode 144: Total Reward = -14.999999999999938, Avg Actor Loss = nan, Avg Critic Loss = 0.1462\n",
      "Episode 145: Total Reward = -17.439999999999884, Avg Actor Loss = nan, Avg Critic Loss = 0.1000\n",
      "Episode 146: Total Reward = -16.839999999999897, Avg Actor Loss = nan, Avg Critic Loss = 0.1076\n",
      "Episode 147: Total Reward = -15.239999999999933, Avg Actor Loss = nan, Avg Critic Loss = 0.1315\n",
      "Episode 148: Total Reward = -15.83999999999992, Avg Actor Loss = nan, Avg Critic Loss = 0.1178\n",
      "Episode 149: Total Reward = -15.439999999999928, Avg Actor Loss = nan, Avg Critic Loss = 0.1310\n",
      "Episode 150: Total Reward = -15.679999999999923, Avg Actor Loss = nan, Avg Critic Loss = 0.1221\n",
      "Episode 151: Total Reward = -15.599999999999925, Avg Actor Loss = nan, Avg Critic Loss = 0.1227\n",
      "Episode 152: Total Reward = -16.439999999999905, Avg Actor Loss = nan, Avg Critic Loss = 0.1137\n",
      "Episode 153: Total Reward = -15.959999999999917, Avg Actor Loss = nan, Avg Critic Loss = 0.1198\n",
      "Episode 154: Total Reward = -18.239999999999867, Avg Actor Loss = nan, Avg Critic Loss = 0.0865\n",
      "Episode 155: Total Reward = -17.319999999999887, Avg Actor Loss = nan, Avg Critic Loss = 0.1015\n",
      "Episode 156: Total Reward = -15.249999999999932, Avg Actor Loss = nan, Avg Critic Loss = 0.1360\n",
      "Episode 157: Total Reward = -15.319999999999931, Avg Actor Loss = nan, Avg Critic Loss = 0.1399\n",
      "Episode 158: Total Reward = -16.319999999999908, Avg Actor Loss = nan, Avg Critic Loss = 0.1120\n",
      "Episode 159: Total Reward = -16.039999999999914, Avg Actor Loss = nan, Avg Critic Loss = 0.1194\n",
      "Episode 160: Total Reward = -15.959999999999917, Avg Actor Loss = nan, Avg Critic Loss = 0.1267\n",
      "Episode 161: Total Reward = -17.279999999999887, Avg Actor Loss = nan, Avg Critic Loss = 0.1008\n",
      "Episode 162: Total Reward = -14.999999999999938, Avg Actor Loss = nan, Avg Critic Loss = 0.1424\n",
      "Episode 163: Total Reward = -15.719999999999922, Avg Actor Loss = nan, Avg Critic Loss = 0.1231\n",
      "Episode 164: Total Reward = -16.359999999999907, Avg Actor Loss = nan, Avg Critic Loss = 0.1062\n",
      "Episode 165: Total Reward = -17.23999999999989, Avg Actor Loss = nan, Avg Critic Loss = 0.0952\n",
      "Episode 166: Total Reward = -15.879999999999919, Avg Actor Loss = nan, Avg Critic Loss = 0.1185\n",
      "Episode 167: Total Reward = -14.799999999999942, Avg Actor Loss = nan, Avg Critic Loss = 0.1419\n",
      "Episode 168: Total Reward = -15.199999999999934, Avg Actor Loss = nan, Avg Critic Loss = 0.1275\n",
      "Episode 169: Total Reward = -14.199999999999955, Avg Actor Loss = nan, Avg Critic Loss = 0.1703\n",
      "Episode 170: Total Reward = -16.959999999999894, Avg Actor Loss = nan, Avg Critic Loss = 0.0999\n",
      "Episode 171: Total Reward = -14.689999999999944, Avg Actor Loss = nan, Avg Critic Loss = 0.1475\n",
      "Episode 172: Total Reward = -17.039999999999893, Avg Actor Loss = nan, Avg Critic Loss = 0.0983\n",
      "Episode 173: Total Reward = -14.719999999999944, Avg Actor Loss = nan, Avg Critic Loss = 0.1335\n",
      "Episode 174: Total Reward = -14.87999999999994, Avg Actor Loss = nan, Avg Critic Loss = 0.1318\n",
      "Episode 175: Total Reward = -17.479999999999883, Avg Actor Loss = nan, Avg Critic Loss = 0.0891\n",
      "Episode 176: Total Reward = -16.6799999999999, Avg Actor Loss = nan, Avg Critic Loss = 0.1009\n",
      "Episode 177: Total Reward = -17.399999999999885, Avg Actor Loss = nan, Avg Critic Loss = 0.0911\n",
      "Episode 178: Total Reward = -17.67999999999988, Avg Actor Loss = nan, Avg Critic Loss = 0.0860\n",
      "Episode 179: Total Reward = -15.83999999999992, Avg Actor Loss = nan, Avg Critic Loss = 0.1154\n",
      "Episode 180: Total Reward = -14.799999999999942, Avg Actor Loss = nan, Avg Critic Loss = 0.1348\n",
      "Episode 181: Total Reward = -14.999999999999938, Avg Actor Loss = nan, Avg Critic Loss = 0.1374\n",
      "Episode 182: Total Reward = -15.159999999999934, Avg Actor Loss = nan, Avg Critic Loss = 0.1324\n",
      "Episode 183: Total Reward = -16.27999999999991, Avg Actor Loss = nan, Avg Critic Loss = 0.1056\n",
      "Episode 184: Total Reward = -17.15999999999989, Avg Actor Loss = nan, Avg Critic Loss = 0.0939\n",
      "Episode 185: Total Reward = -15.719999999999922, Avg Actor Loss = nan, Avg Critic Loss = 0.1129\n",
      "Episode 186: Total Reward = -16.559999999999903, Avg Actor Loss = nan, Avg Critic Loss = 0.1052\n",
      "Episode 187: Total Reward = -14.719999999999944, Avg Actor Loss = nan, Avg Critic Loss = 0.1358\n",
      "Episode 188: Total Reward = -15.079999999999936, Avg Actor Loss = nan, Avg Critic Loss = 0.1305\n",
      "Episode 189: Total Reward = -15.239999999999933, Avg Actor Loss = nan, Avg Critic Loss = 0.1245\n",
      "Episode 190: Total Reward = -16.919999999999895, Avg Actor Loss = nan, Avg Critic Loss = 0.0965\n",
      "Episode 191: Total Reward = -15.319999999999931, Avg Actor Loss = nan, Avg Critic Loss = 0.1277\n",
      "Episode 192: Total Reward = -15.199999999999934, Avg Actor Loss = nan, Avg Critic Loss = 0.1299\n",
      "Episode 193: Total Reward = -17.23999999999989, Avg Actor Loss = nan, Avg Critic Loss = 0.1023\n",
      "Episode 194: Total Reward = -15.35999999999993, Avg Actor Loss = nan, Avg Critic Loss = 0.1356\n",
      "Episode 195: Total Reward = -14.43999999999995, Avg Actor Loss = nan, Avg Critic Loss = 0.1554\n",
      "Episode 196: Total Reward = -18.15999999999987, Avg Actor Loss = nan, Avg Critic Loss = 0.0846\n",
      "Episode 197: Total Reward = -15.639999999999924, Avg Actor Loss = nan, Avg Critic Loss = 0.1114\n",
      "Episode 198: Total Reward = -16.319999999999908, Avg Actor Loss = nan, Avg Critic Loss = 0.1078\n",
      "Episode 199: Total Reward = -16.519999999999904, Avg Actor Loss = nan, Avg Critic Loss = 0.0998\n",
      "Episode 200: Total Reward = -15.79999999999992, Avg Actor Loss = nan, Avg Critic Loss = 0.1099\n",
      "Episode 201: Total Reward = -14.319999999999952, Avg Actor Loss = nan, Avg Critic Loss = 0.1565\n",
      "Episode 202: Total Reward = -18.63999999999986, Avg Actor Loss = nan, Avg Critic Loss = 0.0832\n",
      "Episode 203: Total Reward = -16.839999999999897, Avg Actor Loss = nan, Avg Critic Loss = 0.1010\n",
      "Episode 204: Total Reward = -17.919999999999874, Avg Actor Loss = nan, Avg Critic Loss = 0.0895\n",
      "Episode 205: Total Reward = -16.6799999999999, Avg Actor Loss = nan, Avg Critic Loss = 0.1033\n",
      "Episode 206: Total Reward = -15.199999999999934, Avg Actor Loss = nan, Avg Critic Loss = 0.1322\n",
      "Episode 207: Total Reward = -16.999999999999893, Avg Actor Loss = nan, Avg Critic Loss = 0.0975\n",
      "Episode 208: Total Reward = -16.6799999999999, Avg Actor Loss = nan, Avg Critic Loss = 0.0975\n",
      "Episode 209: Total Reward = -17.11999999999989, Avg Actor Loss = nan, Avg Critic Loss = 0.0947\n",
      "Episode 210: Total Reward = -14.519999999999948, Avg Actor Loss = nan, Avg Critic Loss = 0.1448\n",
      "Episode 211: Total Reward = -15.959999999999917, Avg Actor Loss = nan, Avg Critic Loss = 0.1112\n",
      "Episode 212: Total Reward = -15.999999999999917, Avg Actor Loss = nan, Avg Critic Loss = 0.1144\n",
      "Episode 213: Total Reward = -16.479999999999905, Avg Actor Loss = nan, Avg Critic Loss = 0.1035\n",
      "Episode 214: Total Reward = -16.19999999999991, Avg Actor Loss = nan, Avg Critic Loss = 0.1176\n",
      "Episode 215: Total Reward = -15.32999999999993, Avg Actor Loss = nan, Avg Critic Loss = 0.1249\n",
      "Episode 216: Total Reward = -17.07999999999989, Avg Actor Loss = nan, Avg Critic Loss = 0.0990\n",
      "Episode 217: Total Reward = -16.959999999999894, Avg Actor Loss = nan, Avg Critic Loss = 0.0974\n",
      "Episode 218: Total Reward = -15.559999999999926, Avg Actor Loss = nan, Avg Critic Loss = 0.1211\n",
      "Episode 219: Total Reward = -16.039999999999914, Avg Actor Loss = nan, Avg Critic Loss = 0.1142\n",
      "Episode 220: Total Reward = -15.479999999999928, Avg Actor Loss = nan, Avg Critic Loss = 0.1171\n",
      "Episode 221: Total Reward = -16.359999999999907, Avg Actor Loss = nan, Avg Critic Loss = 0.1006\n",
      "Episode 222: Total Reward = -14.599999999999946, Avg Actor Loss = nan, Avg Critic Loss = 0.1446\n",
      "Episode 223: Total Reward = -18.329999999999867, Avg Actor Loss = nan, Avg Critic Loss = 0.0847\n",
      "Episode 224: Total Reward = -16.839999999999897, Avg Actor Loss = nan, Avg Critic Loss = 0.0966\n",
      "Episode 225: Total Reward = -13.559999999999969, Avg Actor Loss = nan, Avg Critic Loss = 0.1948\n",
      "Episode 226: Total Reward = -15.279999999999932, Avg Actor Loss = nan, Avg Critic Loss = 0.1327\n",
      "Episode 227: Total Reward = -16.839999999999897, Avg Actor Loss = nan, Avg Critic Loss = 0.0997\n",
      "Episode 228: Total Reward = -16.439999999999905, Avg Actor Loss = nan, Avg Critic Loss = 0.1011\n",
      "Episode 229: Total Reward = -16.6399999999999, Avg Actor Loss = nan, Avg Critic Loss = 0.1089\n",
      "Episode 230: Total Reward = -18.11999999999987, Avg Actor Loss = nan, Avg Critic Loss = 0.0908\n",
      "Episode 231: Total Reward = -19.029999999999852, Avg Actor Loss = nan, Avg Critic Loss = 0.0771\n",
      "Episode 232: Total Reward = -17.109999999999893, Avg Actor Loss = nan, Avg Critic Loss = 0.0970\n",
      "Episode 233: Total Reward = -17.319999999999887, Avg Actor Loss = nan, Avg Critic Loss = 0.0922\n",
      "Episode 234: Total Reward = -16.6799999999999, Avg Actor Loss = nan, Avg Critic Loss = 0.1057\n",
      "Episode 235: Total Reward = -14.599999999999946, Avg Actor Loss = nan, Avg Critic Loss = 0.1473\n",
      "Episode 236: Total Reward = -17.399999999999885, Avg Actor Loss = nan, Avg Critic Loss = 0.1031\n",
      "Episode 237: Total Reward = -17.23999999999989, Avg Actor Loss = nan, Avg Critic Loss = 0.1047\n",
      "Episode 238: Total Reward = -16.359999999999907, Avg Actor Loss = nan, Avg Critic Loss = 0.1083\n",
      "Episode 239: Total Reward = -16.6399999999999, Avg Actor Loss = nan, Avg Critic Loss = 0.0997\n",
      "Episode 240: Total Reward = -16.319999999999908, Avg Actor Loss = nan, Avg Critic Loss = 0.1203\n",
      "Episode 241: Total Reward = -17.039999999999893, Avg Actor Loss = nan, Avg Critic Loss = 0.1023\n",
      "Episode 242: Total Reward = -16.359999999999907, Avg Actor Loss = nan, Avg Critic Loss = 0.1110\n",
      "Episode 243: Total Reward = -14.679999999999945, Avg Actor Loss = nan, Avg Critic Loss = 0.1414\n",
      "Episode 244: Total Reward = -15.159999999999934, Avg Actor Loss = nan, Avg Critic Loss = 0.1283\n",
      "Episode 245: Total Reward = -15.759999999999922, Avg Actor Loss = nan, Avg Critic Loss = 0.1165\n",
      "Episode 246: Total Reward = -15.159999999999934, Avg Actor Loss = nan, Avg Critic Loss = 0.1269\n",
      "Episode 247: Total Reward = -17.67999999999988, Avg Actor Loss = nan, Avg Critic Loss = 0.0914\n",
      "Episode 248: Total Reward = -15.879999999999919, Avg Actor Loss = nan, Avg Critic Loss = 0.1180\n",
      "Episode 249: Total Reward = -17.11999999999989, Avg Actor Loss = nan, Avg Critic Loss = 0.1040\n",
      "Episode 250: Total Reward = -14.519999999999948, Avg Actor Loss = nan, Avg Critic Loss = 0.1499\n",
      "Episode 251: Total Reward = -17.07999999999989, Avg Actor Loss = nan, Avg Critic Loss = 0.0944\n",
      "Episode 252: Total Reward = -15.239999999999933, Avg Actor Loss = nan, Avg Critic Loss = 0.1323\n",
      "Episode 253: Total Reward = -15.35999999999993, Avg Actor Loss = nan, Avg Critic Loss = 0.1207\n",
      "Episode 254: Total Reward = -16.399999999999906, Avg Actor Loss = nan, Avg Critic Loss = 0.1031\n",
      "Episode 255: Total Reward = -15.679999999999923, Avg Actor Loss = nan, Avg Critic Loss = 0.1137\n",
      "Episode 256: Total Reward = -16.399999999999906, Avg Actor Loss = nan, Avg Critic Loss = 0.1045\n",
      "Episode 257: Total Reward = -16.119999999999912, Avg Actor Loss = nan, Avg Critic Loss = 0.1073\n",
      "Episode 258: Total Reward = -15.039999999999937, Avg Actor Loss = nan, Avg Critic Loss = 0.1366\n",
      "Episode 259: Total Reward = -14.279999999999953, Avg Actor Loss = nan, Avg Critic Loss = 0.1540\n",
      "Episode 260: Total Reward = -15.959999999999917, Avg Actor Loss = nan, Avg Critic Loss = 0.1223\n",
      "Episode 261: Total Reward = -16.599999999999902, Avg Actor Loss = nan, Avg Critic Loss = 0.1081\n",
      "Episode 262: Total Reward = -15.319999999999931, Avg Actor Loss = nan, Avg Critic Loss = 0.1251\n",
      "Episode 263: Total Reward = -18.239999999999867, Avg Actor Loss = nan, Avg Critic Loss = 0.0857\n",
      "Episode 264: Total Reward = -14.479999999999949, Avg Actor Loss = nan, Avg Critic Loss = 0.1401\n",
      "Episode 265: Total Reward = -17.67999999999988, Avg Actor Loss = nan, Avg Critic Loss = 0.0876\n",
      "Episode 266: Total Reward = -17.719999999999878, Avg Actor Loss = nan, Avg Critic Loss = 0.0957\n",
      "Episode 267: Total Reward = -16.039999999999914, Avg Actor Loss = nan, Avg Critic Loss = 0.1094\n",
      "Episode 268: Total Reward = -16.119999999999912, Avg Actor Loss = nan, Avg Critic Loss = 0.1072\n",
      "Episode 269: Total Reward = -15.719999999999922, Avg Actor Loss = nan, Avg Critic Loss = 0.1238\n",
      "Episode 270: Total Reward = -15.719999999999922, Avg Actor Loss = nan, Avg Critic Loss = 0.1200\n",
      "Episode 271: Total Reward = -16.359999999999907, Avg Actor Loss = nan, Avg Critic Loss = 0.1059\n",
      "Episode 272: Total Reward = -15.479999999999928, Avg Actor Loss = nan, Avg Critic Loss = 0.1154\n",
      "Episode 273: Total Reward = -15.719999999999922, Avg Actor Loss = nan, Avg Critic Loss = 0.1124\n",
      "Episode 274: Total Reward = -15.999999999999917, Avg Actor Loss = nan, Avg Critic Loss = 0.1082\n",
      "Episode 275: Total Reward = -14.679999999999945, Avg Actor Loss = nan, Avg Critic Loss = 0.1374\n",
      "Episode 276: Total Reward = -16.479999999999905, Avg Actor Loss = nan, Avg Critic Loss = 0.1013\n",
      "Episode 277: Total Reward = -15.559999999999926, Avg Actor Loss = nan, Avg Critic Loss = 0.1284\n",
      "Episode 278: Total Reward = -16.039999999999914, Avg Actor Loss = nan, Avg Critic Loss = 0.1083\n",
      "Episode 279: Total Reward = -15.479999999999928, Avg Actor Loss = nan, Avg Critic Loss = 0.1212\n",
      "Episode 280: Total Reward = -18.55999999999986, Avg Actor Loss = nan, Avg Critic Loss = 0.0757\n",
      "Episode 281: Total Reward = -16.7199999999999, Avg Actor Loss = nan, Avg Critic Loss = 0.1022\n",
      "Episode 282: Total Reward = -16.319999999999908, Avg Actor Loss = nan, Avg Critic Loss = 0.1044\n",
      "Episode 283: Total Reward = -15.79999999999992, Avg Actor Loss = nan, Avg Critic Loss = 0.1204\n",
      "Episode 284: Total Reward = -19.11999999999985, Avg Actor Loss = nan, Avg Critic Loss = 0.0756\n",
      "Episode 285: Total Reward = -16.359999999999907, Avg Actor Loss = nan, Avg Critic Loss = 0.1147\n",
      "Episode 286: Total Reward = -16.919999999999895, Avg Actor Loss = nan, Avg Critic Loss = 0.0989\n",
      "Episode 287: Total Reward = -16.23999999999991, Avg Actor Loss = nan, Avg Critic Loss = 0.0992\n",
      "Episode 288: Total Reward = -17.279999999999887, Avg Actor Loss = nan, Avg Critic Loss = 0.0874\n",
      "Episode 289: Total Reward = -14.159999999999956, Avg Actor Loss = nan, Avg Critic Loss = 0.1535\n",
      "Episode 290: Total Reward = -17.039999999999893, Avg Actor Loss = nan, Avg Critic Loss = 0.0918\n",
      "Episode 291: Total Reward = -16.559999999999903, Avg Actor Loss = nan, Avg Critic Loss = 0.0980\n",
      "Episode 292: Total Reward = -14.719999999999944, Avg Actor Loss = nan, Avg Critic Loss = 0.1418\n",
      "Episode 293: Total Reward = -18.679999999999858, Avg Actor Loss = nan, Avg Critic Loss = 0.0798\n",
      "Episode 294: Total Reward = -17.999999999999872, Avg Actor Loss = nan, Avg Critic Loss = 0.0866\n",
      "Episode 295: Total Reward = -15.159999999999934, Avg Actor Loss = nan, Avg Critic Loss = 0.1294\n",
      "Episode 296: Total Reward = -15.199999999999934, Avg Actor Loss = nan, Avg Critic Loss = 0.1224\n",
      "Episode 297: Total Reward = -14.959999999999939, Avg Actor Loss = nan, Avg Critic Loss = 0.1264\n",
      "Episode 298: Total Reward = -15.879999999999919, Avg Actor Loss = nan, Avg Critic Loss = 0.1133\n",
      "Episode 299: Total Reward = -17.519999999999882, Avg Actor Loss = nan, Avg Critic Loss = 0.0986\n",
      "Episode 300: Total Reward = -15.679999999999923, Avg Actor Loss = nan, Avg Critic Loss = 0.1243\n",
      "Episode 301: Total Reward = -15.479999999999928, Avg Actor Loss = nan, Avg Critic Loss = 0.1226\n",
      "Episode 302: Total Reward = -16.079999999999913, Avg Actor Loss = nan, Avg Critic Loss = 0.1206\n",
      "Episode 303: Total Reward = -16.079999999999913, Avg Actor Loss = nan, Avg Critic Loss = 0.1128\n",
      "Episode 304: Total Reward = -16.039999999999914, Avg Actor Loss = nan, Avg Critic Loss = 0.1140\n",
      "Episode 305: Total Reward = -15.079999999999936, Avg Actor Loss = nan, Avg Critic Loss = 0.1348\n",
      "Episode 306: Total Reward = -15.919999999999918, Avg Actor Loss = nan, Avg Critic Loss = 0.1165\n",
      "Episode 307: Total Reward = -15.879999999999919, Avg Actor Loss = nan, Avg Critic Loss = 0.1132\n",
      "Episode 308: Total Reward = -18.279999999999866, Avg Actor Loss = nan, Avg Critic Loss = 0.0836\n",
      "Episode 309: Total Reward = -15.079999999999936, Avg Actor Loss = nan, Avg Critic Loss = 0.1380\n",
      "Episode 310: Total Reward = -17.15999999999989, Avg Actor Loss = nan, Avg Critic Loss = 0.0985\n",
      "Episode 311: Total Reward = -18.359999999999864, Avg Actor Loss = nan, Avg Critic Loss = 0.0847\n"
     ]
    }
   ],
   "source": [
    "gym.register_envs(ale_py)\n",
    "env = gym.make(\"ALE/Tetris-v5\", render_mode=\"human\")\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "state, _ = env.reset()\n",
    "save_dir = \"training_logs2\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "print(dir(env))\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, action_dim, hidden_dim=128):\n",
    "        super(Actor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
    "\n",
    "        # Use a dummy input to calculate the flattened size after conv layers\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 3, state.shape[0], state.shape[1])\n",
    "            conv_output = self.conv_layers(dummy_input)\n",
    "            conv_output_size = conv_output.view(-1).size(0)\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(conv_output_size, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "    def conv_layers(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = self.conv_layers(state)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        action_probs = torch.softmax(self.fc2(x), dim=-1)\n",
    "        return action_probs\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super(Critic, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=8, stride=4)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=4, stride=2)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 3, state.shape[0], state.shape[1])\n",
    "            conv_output = self.conv_layers(dummy_input)\n",
    "            conv_output_size = conv_output.view(-1).size(0)\n",
    "\n",
    "        self.fc1 = nn.Linear(conv_output_size, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def conv_layers(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = self.conv_layers(state)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        state_value = self.fc2(x)\n",
    "        return state_value\n",
    "\n",
    "def calculate_reward(lines_cleared, game_over):\n",
    "    if game_over:\n",
    "        return game_over_penalty\n",
    "    elif lines_cleared > 0:\n",
    "        return line_clear_reward * lines_cleared\n",
    "    else:\n",
    "        return step_penalty\n",
    "\n",
    "def train_step(state, action, reward, next_state, done):\n",
    "    state = torch.tensor(state, dtype=torch.float32).unsqueeze(0).permute(0, 3, 1, 2) / 255.0\n",
    "    next_state = torch.tensor(next_state, dtype=torch.float32).unsqueeze(0).permute(0, 3, 1, 2) / 255.0\n",
    "    action = torch.tensor(action, dtype=torch.long)\n",
    "    reward = torch.tensor(reward, dtype=torch.float32)\n",
    "\n",
    "    # Critic update with gradient clipping\n",
    "    value = critic(state)\n",
    "    next_value = critic(next_state) * (1 - done)\n",
    "    target_value = reward + gamma * next_value\n",
    "    critic_loss = (value - target_value.detach()) ** 2\n",
    "\n",
    "    critic_optimizer.zero_grad()\n",
    "    critic_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(critic.parameters(), max_norm=1.0)\n",
    "    critic_optimizer.step()\n",
    "\n",
    "    # Actor update with gradient clipping\n",
    "    advantage = (target_value - value).detach()\n",
    "    action_probs = actor(state)\n",
    "    log_prob = torch.log(action_probs.squeeze(0)[action])\n",
    "    actor_loss = -log_prob * advantage\n",
    "\n",
    "    actor_optimizer.zero_grad()\n",
    "    actor_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(actor.parameters(), max_norm=1.0)\n",
    "    actor_optimizer.step()\n",
    "\n",
    "    return actor_loss.item(), critic_loss.item()\n",
    "\n",
    "# Actor and Critic networks and optimizers\n",
    "actor = Actor(action_dim=env.action_space.n)\n",
    "critic = Critic()\n",
    "actor_optimizer = optim.Adam(actor.parameters(), lr=learning_rate)\n",
    "critic_optimizer = optim.Adam(critic.parameters(), lr=learning_rate)\n",
    "print(action_dim)\n",
    "\n",
    "# parameters and metrics\n",
    "def save_parameters_and_metrics(episode, actor, critic, actor_optimizer, critic_optimizer, metrics):\n",
    "    torch.save({\n",
    "        'actor_state_dict': actor.state_dict(),\n",
    "        'critic_state_dict': critic.state_dict(),\n",
    "        'actor_optimizer_state_dict': actor_optimizer.state_dict(),\n",
    "        'critic_optimizer_state_dict': critic_optimizer.state_dict()\n",
    "    }, os.path.join(save_dir, f\"model_checkpoint_ep{episode}.pt\"))\n",
    "\n",
    "    with open(os.path.join(save_dir, \"training_metrics.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(metrics, f)\n",
    "\n",
    "metrics = {\n",
    "    \"episode_rewards\": [],\n",
    "    \"step_actor_losses\": [],\n",
    "    \"step_critic_losses\": []\n",
    "}\n",
    "\n",
    "# Define a function to print the average weights and losses\n",
    "def print_parameters_and_losses(actor, critic, episode, avg_actor_loss, avg_critic_loss):\n",
    "    print(f\"\\n--- Statistics at Episode {episode} ---\")\n",
    "    \n",
    "    # Print the average weight of specific layers\n",
    "    actor_conv1_avg = actor.conv1.weight.data.mean().item()\n",
    "    print(f\"Actor Layer 1 Conv Weights Average: {actor_conv1_avg}\")\n",
    "    \n",
    "    actor_fc1_avg = actor.fc1.weight.data.mean().item()\n",
    "    print(f\"Actor Layer 1 FC Weights Average: {actor_fc1_avg}\")\n",
    "    \n",
    "    critic_conv1_avg = critic.conv1.weight.data.mean().item()\n",
    "    print(f\"Critic Layer 1 Conv Weights Average: {critic_conv1_avg}\")\n",
    "    \n",
    "    critic_fc1_avg = critic.fc1.weight.data.mean().item()\n",
    "    print(f\"Critic Layer 1 FC Weights Average: {critic_fc1_avg}\")\n",
    "\n",
    "    # Print average losses for actor and critic\n",
    "    print(f\"Average Actor Loss: {avg_actor_loss}\")\n",
    "    print(f\"Average Critic Loss: {avg_critic_loss}\")\n",
    "    \n",
    "    print(\"--- End of Statistics ---\\n\")\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    actor_losses = []\n",
    "    critic_losses = []\n",
    "\n",
    "    while not done:\n",
    "        # Preprocess state for model input\n",
    "        state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0).permute(0, 3, 1, 2) / 255.0\n",
    "\n",
    "        # Get action probabilities from the actor network\n",
    "        action_probs = actor(state_tensor).detach().numpy().squeeze()\n",
    "\n",
    "        # ε-greedy action selection\n",
    "        if np.random.rand() < epsilon:\n",
    "            # Exploration: choose a random action\n",
    "            action = np.random.choice(action_dim)\n",
    "        else:\n",
    "            # Exploitation: choose the action with the highest probability\n",
    "            action = np.argmax(action_probs)\n",
    "\n",
    "        # Decay epsilon after each step\n",
    "        epsilon = max(epsilon * epsilon_decay, epsilon_min)\n",
    "\n",
    "        # Take the action in the environment\n",
    "        next_state, _, done, _, info = env.step(action)\n",
    "        \n",
    "        # Calculate reward\n",
    "        lines_cleared = info.get(\"lines_cleared\", 0)\n",
    "        reward = calculate_reward(lines_cleared, done)\n",
    "        episode_reward += reward\n",
    "\n",
    "        # Train actor and critic networks\n",
    "        actor_loss, critic_loss = train_step(state, action, reward, next_state, done)\n",
    "\n",
    "        # Log losses for each step\n",
    "        actor_losses.append(actor_loss)\n",
    "        critic_losses.append(critic_loss)\n",
    "\n",
    "        # Update the state\n",
    "        state = next_state\n",
    "\n",
    "    # Calculate average losses for this episode\n",
    "    avg_actor_loss = np.mean(actor_losses)\n",
    "    avg_critic_loss = np.mean(critic_losses)\n",
    "\n",
    "    # Print the episode results with average losses\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {episode_reward}, Avg Actor Loss = {avg_actor_loss:.4f}, Avg Critic Loss = {avg_critic_loss:.4f}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fa772b-47b2-4dca-841b-cd6c22dae845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
